{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a11d13",
   "metadata": {},
   "source": [
    "# catnip\n",
    "## Basic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40d49a",
   "metadata": {},
   "source": [
    "### Colab only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# clone repo\n",
    "if not os.path.exists(\"/content/catnip\"):\n",
    "    !git clone -b yolo-bbo --recurse-submodules https://github.com/rifusaki/catnip.git\n",
    "    %cd /content/catnip\n",
    "else:\n",
    "    %cd /content/catnip\n",
    "    !git pull\n",
    "\n",
    "# google auth\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# gcsfuse\n",
    "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
    "!apt -qq update\n",
    "!apt -qq install gcsfuse\n",
    "\n",
    "# mount bucket\n",
    "!mkdir -p /content/gcs\n",
    "!gcsfuse --implicit-dirs catnip-data /content/gcs\n",
    "\n",
    "# link bucket to expected data path in pipeline.yaml\n",
    "# pipeline.yaml expects 'catnip-data/' in the repo root\n",
    "!ln -s /content/gcs /content/catnip/catnip-data\n",
    "\n",
    "# install packages if needed\n",
    "%pip install ultralytics pydantic pydantic-settings omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ea118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path configuration\n",
    "from pathlib import Path\n",
    "\n",
    "# define repo root\n",
    "repo_root = Path(\"/content/catnip\").resolve()\n",
    "\n",
    "# add to sys.path\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.append(str(repo_root))\n",
    "\n",
    "# change working directory\n",
    "os.chdir(repo_root)\n",
    "print(f\"Working directory set to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994cc05",
   "metadata": {},
   "source": [
    "### Local only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880f16d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /home/rifubuntu/catnip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# after cloning rifusaki/catnip\n",
    "# add repository root to path\n",
    "repo_root = Path(\"..\").resolve()\n",
    "\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.append(str(repo_root))\n",
    "\n",
    "# change working directory to repo root\n",
    "os.chdir(repo_root)\n",
    "print(f\"Working directory set to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d055c0b3",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6efc10",
   "metadata": {},
   "source": [
    "### Paths and run config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43bea325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Root: catnip-data\n",
      "Manga Dir: catnip-data/data/manga\n",
      "Annotations Dir: catnip-data/data/annotations\n",
      "Models Dir: catnip-data/models\n",
      "Runs Dir: catnip-data/runs\n",
      "Output Dir: catnip-data/results\n",
      "Label Studio export Dir: catnip-data/data/ls-exports\n"
     ]
    }
   ],
   "source": [
    "# load configuration\n",
    "from src.config import load_settings\n",
    "\n",
    "settings = load_settings()\n",
    "\n",
    "print(f\"Data Root: {settings.paths.data}\")\n",
    "print(f\"Manga Dir: {settings.paths.manga_dir}\")\n",
    "print(f\"Annotations Dir: {settings.paths.annotations_dir}\")\n",
    "print(f\"Models Dir: {settings.paths.model_dir}\")\n",
    "print(f\"Runs Dir: {settings.paths.runs_dir}\")\n",
    "print(f\"Output Dir: {settings.paths.output_dir}\")\n",
    "print(f\"Label Studio export Dir: {settings.paths.ls_exports_dir}\")\n",
    "\n",
    "run_name = \"0.11.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb441daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created symlink: /home/rifubuntu/catnip/yolo_dataset/images -> /home/rifubuntu/catnip/catnip-data/data/manga\n",
      "Created symlink: /home/rifubuntu/catnip/yolo_dataset/labels -> /home/rifubuntu/catnip/catnip-data/data/annotations\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset for YOLO\n",
    "\n",
    "# we create a local 'yolo_dataset' folder with symlinks to the actual data\n",
    "# this ensures a standard structure (images/labels) regardless of the source layout\n",
    "# in my case I have manga/annotations instead of images/labels\n",
    "from src.training.preparation import safe_symlink\n",
    "\n",
    "dataset_root = repo_root / \"yolo_dataset\"\n",
    "dataset_root.mkdir(exist_ok=True)\n",
    "\n",
    "images_link = dataset_root / \"images\"\n",
    "labels_link = dataset_root / \"labels\"\n",
    "\n",
    "# symlink the actual data to this local structure\n",
    "safe_symlink(settings.paths.manga_dir, images_link)\n",
    "safe_symlink(settings.paths.annotations_dir, labels_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e35f5b",
   "metadata": {},
   "source": [
    "### Training prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03c13b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Label Studio export: catnip-data/data/ls-exports/251228_v1.json\n",
      "Processed 76 tasks. Labels saved to catnip-data/data/annotations\n"
     ]
    }
   ],
   "source": [
    "# for some reason the YOLO export from Label Studio doesn't include the file paths\n",
    "# and since my images are not in a flat structure, I cannot use it directly\n",
    "# so, I export the JSON which includes the paths and convert it to YOLO format here\n",
    "from src.convert_labels import convert_label_studio_to_yolo\n",
    "\n",
    "# define path to Label Studio export (adjust filename as needed)\n",
    "ls_export_dir = settings.paths.ls_exports_dir\n",
    "json_files = list(ls_export_dir.glob(\"*.json\"))\n",
    "\n",
    "if json_files:\n",
    "    # pick the latest one or specific one\n",
    "    json_file = sorted(json_files)[-1] \n",
    "    print(f\"Found Label Studio export: {json_file}\")\n",
    "    \n",
    "    convert_label_studio_to_yolo(\n",
    "        json_file, \n",
    "        settings.paths.annotations_dir, \n",
    "        { \"izutsumi\": 0, \"izutsumi_face\": 1, \"thistle\": 2, \"kabru\": 3 }\n",
    "    )\n",
    "else:\n",
    "    print(f\"No Label Studio JSON export found in {ls_export_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2bbfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating new training list: catnip-data/yoloConfig/251228_v1_train.txt\n",
      "found 2752 total images in 'images' directory.\n",
      "generated catnip-data/yoloConfig/251228_v1_train.txt\n",
      "   - labeled images (subset): 92\n",
      "   - unlabeled images (skipped): 2660\n"
     ]
    }
   ],
   "source": [
    "# Generate Training List\n",
    "from src.training.preparation import generate_training_list\n",
    "\n",
    "# Define config directory for YOLO artifacts\n",
    "config_dir = settings.paths.data / \"yoloConfig\"\n",
    "config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Determine filename\n",
    "if 'json_file' in locals() and json_file.exists():\n",
    "    train_list_name = f\"{json_file.stem}_train.txt\"\n",
    "else:\n",
    "    raise RuntimeError(\"No Label Studio JSON export found; cannot determine training list name.\")\n",
    "    # train_list_name = \"train.txt\"  # --- IGNORE ---\n",
    "\n",
    "train_list_path = config_dir / train_list_name\n",
    "\n",
    "# generate list using the symlinked 'images' directory\n",
    "# this ensures paths in the txt file match what YOLO sees in 'yolo_dataset'\n",
    "# note: We use the *symlinked* path for generation so the txt file contains local paths\n",
    "train_list_path = generate_training_list(\n",
    "    images_link, \n",
    "    labels_link, \n",
    "    train_list_path, \n",
    "    force_regenerate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ad8f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dataset.yaml\n",
      "names:\n",
      "  0: izutsumi\n",
      "  1: izutsumi_face\n",
      "  2: thistle\n",
      "  3: kabru\n",
      "path: /home/rifubuntu/catnip/yolo_dataset\n",
      "train: /home/rifubuntu/catnip/catnip-data/yoloConfig/251228_v1_train.txt\n",
      "val: /home/rifubuntu/catnip/catnip-data/yoloConfig/251228_v1_train.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataset.yaml\n",
    "import importlib\n",
    "import src.training.preparation\n",
    "importlib.reload(src.training.preparation)\n",
    "from src.training.preparation import create_dataset_yaml\n",
    "\n",
    "dataset_yaml_path = create_dataset_yaml(\n",
    "    path=dataset_root, # Point to the local dataset root containing images/ and labels/\n",
    "    train_path=train_list_path,\n",
    "    val_path=train_list_path,\n",
    "    names={0: 'izutsumi', 1: 'izutsumi_face', 2: 'thistle', 3: 'kabru'}\n",
    ")\n",
    "\n",
    "with open(dataset_yaml_path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d6cdb",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1536ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel Extension for PyTorch not found\n",
      "/home/rifubuntu/catnip/.pixi/envs/default/lib/python3.11/site-packages/intel_extension_for_pytorch/lib/libintel-ext-pt-cpu.so: undefined symbol: _ZNK5torch8autograd4Node4nameEv\n",
      "Using device: cpu\n",
      "Ultralytics 8.3.241 ðŸš€ Python-3.11.14 torch-2.4.0.post101 CPU (Intel Core i5-8250U 1.60GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=0.11.1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=catnip-data/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/rifubuntu/catnip/catnip-data/runs/0.11.1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820956  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,429,340 parameters, 9,429,324 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.1Â±0.0 ms, read: 127.7Â±61.1 MB/s, size: 638.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/rifubuntu/catnip/yolo_dataset/labels/v01... 92 images, 16 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 92/92 280.1it/s 0.3s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/rifubuntu/catnip/yolo_dataset/labels/v01.cache\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolo11s.pt\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset_yaml_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m.\u001b[49m\u001b[43mruns_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/engine/model.py:773\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    770\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    771\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/engine/trainer.py:243\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    240\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/engine/trainer.py:364\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.world_size > \u001b[32m1\u001b[39m:\n\u001b[32m    363\u001b[39m     \u001b[38;5;28mself\u001b[39m._setup_ddp()\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    366\u001b[39m nb = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[32m    367\u001b[39m nw = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m.args.warmup_epochs * nb), \u001b[32m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.warmup_epochs > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m -\u001b[32m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/engine/trainer.py:327\u001b[39m, in \u001b[36mBaseTrainer._setup_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28mself\u001b[39m.train_loader = \u001b[38;5;28mself\u001b[39m.get_dataloader(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m.data[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m], batch_size=batch_size, rank=LOCAL_RANK, mode=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m )\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[38;5;28mself\u001b[39m.test_loader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLOCAL_RANK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28mself\u001b[39m.validator = \u001b[38;5;28mself\u001b[39m.get_validator()\n\u001b[32m    334\u001b[39m \u001b[38;5;28mself\u001b[39m.ema = ModelEMA(\u001b[38;5;28mself\u001b[39m.model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/models/yolo/detect/train.py:93\u001b[39m, in \u001b[36mDetectionTrainer.get_dataloader\u001b[39m\u001b[34m(self, dataset_path, batch_size, rank, mode)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m}, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMode must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(rank):  \u001b[38;5;66;03m# init dataset *.cache only once if DDP\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m shuffle = mode == \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(dataset, \u001b[33m\"\u001b[39m\u001b[33mrect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m shuffle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/models/yolo/detect/train.py:77\u001b[39m, in \u001b[36mDetectionTrainer.build_dataset\u001b[39m\u001b[34m(self, img_path, mode, batch)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build YOLO Dataset for training or validation.\u001b[39;00m\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m \u001b[33;03m    (Dataset): YOLO dataset object configured for the specified mode.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     76\u001b[39m gs = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(unwrap_model(\u001b[38;5;28mself\u001b[39m.model).stride.max() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m), \u001b[32m32\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_yolo_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/data/build.py:236\u001b[39m, in \u001b[36mbuild_yolo_dataset\u001b[39m\u001b[34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[39;00m\n\u001b[32m    235\u001b[39m dataset = YOLOMultiModalDataset \u001b[38;5;28;01mif\u001b[39;00m multi_modal \u001b[38;5;28;01melse\u001b[39;00m YOLODataset\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# augmentation\u001b[39;49;00m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: probably add a get_hyps_from_cfg function\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrect\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# rectangular batches\u001b[39;49;00m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolorstr\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfraction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfraction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/data/dataset.py:88\u001b[39m, in \u001b[36mYOLODataset.__init__\u001b[39m\u001b[34m(self, data, task, *args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.data = data\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.use_segments \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_keypoints), \u001b[33m\"\u001b[39m\u001b[33mCan not use both segments and keypoints.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchannels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/data/base.py:117\u001b[39m, in \u001b[36mBaseDataset.__init__\u001b[39m\u001b[34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m.channels = channels\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m.cv2_flag = cv2.IMREAD_GRAYSCALE \u001b[38;5;28;01mif\u001b[39;00m channels == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m cv2.IMREAD_COLOR\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28mself\u001b[39m.im_files = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_img_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mself\u001b[39m.labels = \u001b[38;5;28mself\u001b[39m.get_labels()\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.update_labels(include_class=classes)  \u001b[38;5;66;03m# single_cls and include_class\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/data/base.py:184\u001b[39m, in \u001b[36mBaseDataset.get_img_files\u001b[39m\u001b[34m(self, img_path)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fraction < \u001b[32m1\u001b[39m:\n\u001b[32m    183\u001b[39m     im_files = im_files[: \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mlen\u001b[39m(im_files) * \u001b[38;5;28mself\u001b[39m.fraction)]  \u001b[38;5;66;03m# retain a fraction of the dataset\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[43mcheck_file_speeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# check image read speeds\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m im_files\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/catnip/.pixi/envs/default/lib/python3.11/site-packages/ultralytics/data/utils.py:94\u001b[39m, in \u001b[36mcheck_file_speeds\u001b[39m\u001b[34m(files, threshold_ms, threshold_mb, max_files, prefix)\u001b[39m\n\u001b[32m     92\u001b[39m start = time.perf_counter()\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(f, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_obj:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     _ = file_obj.read()\n\u001b[32m     95\u001b[39m read_time = time.perf_counter() - start\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read_time > \u001b[32m0\u001b[39m:  \u001b[38;5;66;03m# Avoid division by zero\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Determine device - PyTorch 2.6+ has native XPU support\n",
    "if torch.xpu.is_available():\n",
    "    device = 'xpu'\n",
    "    print(f\"Using Intel XPU: {torch.xpu.get_device_name(0)}\")\n",
    "else:\n",
    "    device = settings.params.device\n",
    "    print(f\"XPU not available, using: {device}\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "model = YOLO(\"yolo11s.pt\") \n",
    "\n",
    "results = model.train(\n",
    "    data=str(dataset_yaml_path),\n",
    "    epochs=100,\n",
    "    imgsz=settings.params.img_size,\n",
    "    project=str(settings.paths.runs_dir),\n",
    "    name=run_name,\n",
    "    device=device,\n",
    "    cache=False,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98542ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "from src.training.preparation import save_best_model\n",
    "\n",
    "save_best_model(\n",
    "    project_dir=settings.paths.runs_dir,\n",
    "    run_name=run_name,\n",
    "    target_dir=settings.paths.model_dir,\n",
    "    target_name=f\"yolo11_izutsumi_{run_name}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228118fd",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from src.output.output import save_inference_results\n",
    "import torch\n",
    "\n",
    "# Determine device - PyTorch 2.6+ has native XPU support\n",
    "if torch.xpu.is_available():\n",
    "    device = 'xpu'\n",
    "    print(f\"Using Intel XPU: {torch.xpu.get_device_name(0)}\")\n",
    "else:\n",
    "    device = settings.params.device\n",
    "    print(f\"XPU not available, using: {device}\")\n",
    "\n",
    "# Load the trained model\n",
    "model_path = settings.paths.runs_dir / run_name / \"weights\" / \"best.pt\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f\"Model not found at {model_path}\")\n",
    "else:\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Define output directories\n",
    "    output_dir = settings.paths.output_dir\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    inference_source = settings.paths.manga_dir\n",
    "    print(f\"Running inference on {inference_source}...\")\n",
    "\n",
    "    # Run prediction\n",
    "    results = model.predict(\n",
    "        source=str(inference_source) + \"/**/*.*\",\n",
    "        project=str(output_dir),\n",
    "        name=run_name,\n",
    "        save=False,\n",
    "        save_txt=False,\n",
    "        conf=0.25,\n",
    "        stream=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    save_inference_results(results, output_dir, inference_source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
