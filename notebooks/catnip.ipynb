{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d232c2",
   "metadata": {},
   "source": [
    "# Catnip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0268ef9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d790b",
   "metadata": {},
   "source": [
    "### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56767293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scripts for Colab ---\n",
    "# Clone repo\n",
    "!git clone -b yolo-finetune --recurse-submodules https://github.com/rifusaki/catnip.git\n",
    "%cd /content/catnip\n",
    "\n",
    "# Authenticate with Google\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Install gcsfuse\n",
    "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
    "!apt -qq update\n",
    "!apt -qq install gcsfuse\n",
    "\n",
    "# Mount bucket\n",
    "!mkdir -p /content/catnip/data\n",
    "!gcsfuse --implicit-dirs catnip-data /content/catnip/data\n",
    "\n",
    "# Install packages not included in Colab\n",
    "%pip install ultralytics pydantic pydantic-settings omegaconf\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(str(Path.cwd())+'/catnip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e836c0",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6626adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload for debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc37b22",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faec48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /Users/rifusaki/repos/catnip\n"
     ]
    }
   ],
   "source": [
    "# Dependencies and configuration\n",
    "from src.config import settings, setup_dirs\n",
    "\n",
    "print(\"Working directory set to:\", Path.cwd())\n",
    "izutsumiPaths, notIzutsumiPaths = setup_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9572788",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7b7ba",
   "metadata": {},
   "source": [
    "### Panel extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5439a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.coreMPE.src.adenzu_panel.image_processing import panel\n",
    "\n",
    "\n",
    "_ = panel.extract_panels_for_images_in_folder_recursive(\n",
    "    input_dir=str(settings.paths.pages_dir),\n",
    "    output_dir=str(settings.paths.panels_dir),\n",
    "    split_joint_panels=False,   # maps to --split-joint-panels\n",
    "    fallback=True              # maps to --fallback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e7198",
   "metadata": {},
   "source": [
    "### Head crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bbf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.headExtraction import anime_extraction_recursive\n",
    "\n",
    "\n",
    "valid_exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "panel_paths = sorted(\n",
    "    [p for p in settings.paths.panels_dir.iterdir() if p.suffix.lower() in valid_exts]\n",
    ")\n",
    "num_crops = anime_extraction_recursive()\n",
    "\n",
    "print(f\"Extracted {num_crops} faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfcd928",
   "metadata": {},
   "source": [
    "## Catnip core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d86d2d",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1156e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Izutsumi: 181 | Not Izutsumi: 63\n",
      "not implemented xd\n",
      "Data prepared in data/recognition/izutsumiTraining\n"
     ]
    }
   ],
   "source": [
    "from src.training.preparation import prepare_data\n",
    "\n",
    "prepare_data(izutsumiPaths, notIzutsumiPaths, version=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902308d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac349522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n",
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False        2592       [96, 3, 3, 3] -0.000392     0.151        float32\n",
      "    1                       model.0.bn.weight         BatchNorm2d     False          96                [96]      1.42      1.48        float32\n",
      "    1                         model.0.bn.bias         BatchNorm2d     False          96                [96]    -0.407      2.61        float32\n",
      "    2                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    3                     model.1.conv.weight              Conv2d     False      165888     [192, 96, 3, 3] -0.000697    0.0306        float32\n",
      "    4                       model.1.bn.weight         BatchNorm2d     False         192               [192]      4.73      1.35        float32\n",
      "    4                         model.1.bn.bias         BatchNorm2d     False         192               [192]    -0.782      1.98        float32\n",
      "    5                 model.2.cv1.conv.weight              Conv2d     False       36864    [192, 192, 1, 1]  -0.00645    0.0538        float32\n",
      "    6                   model.2.cv1.bn.weight         BatchNorm2d     False         192               [192]      2.88       1.4        float32\n",
      "    6                     model.2.cv1.bn.bias         BatchNorm2d     False         192               [192]    -0.183       1.7        float32\n",
      "    7                 model.2.cv2.conv.weight              Conv2d     False      147456    [384, 384, 1, 1]  -0.00195    0.0311        float32\n",
      "    8                   model.2.cv2.bn.weight         BatchNorm2d     False         384               [384]      1.51     0.406        float32\n",
      "    8                     model.2.cv2.bn.bias         BatchNorm2d     False         384               [384]     -1.92      1.11        float32\n",
      "    9             model.2.m.0.cv1.conv.weight              Conv2d     False        4608      [48, 96, 1, 1]   -0.0027    0.0649        float32\n",
      "   10               model.2.m.0.cv1.bn.weight         BatchNorm2d     False          48                [48]      1.99      1.03        float32\n",
      "   10                 model.2.m.0.cv1.bn.bias         BatchNorm2d     False          48                [48]     0.229      2.58        float32\n",
      "   11             model.2.m.0.cv2.conv.weight              Conv2d     False        4608      [48, 96, 1, 1]  -0.00199    0.0529        float32\n",
      "   12               model.2.m.0.cv2.bn.weight         BatchNorm2d     False          48                [48]      2.41     0.683        float32\n",
      "   12                 model.2.m.0.cv2.bn.bias         BatchNorm2d     False          48                [48]    -0.624      1.35        float32\n",
      "   13             model.2.m.0.cv3.conv.weight              Conv2d     False        9216      [96, 96, 1, 1]  -0.00456    0.0625        float32\n",
      "   14               model.2.m.0.cv3.bn.weight         BatchNorm2d     False          96                [96]      2.69     0.466        float32\n",
      "   14                 model.2.m.0.cv3.bn.bias         BatchNorm2d     False          96                [96]   -0.0842      1.63        float32\n",
      "   15         model.2.m.0.m.0.cv1.conv.weight              Conv2d     False       20736      [48, 48, 3, 3]  -0.00146    0.0329        float32\n",
      "   16           model.2.m.0.m.0.cv1.bn.weight         BatchNorm2d     False          48                [48]      1.77      0.75        float32\n",
      "   16             model.2.m.0.m.0.cv1.bn.bias         BatchNorm2d     False          48                [48]    -0.913      2.17        float32\n",
      "   17         model.2.m.0.m.0.cv2.conv.weight              Conv2d     False       20736      [48, 48, 3, 3]  -0.00156    0.0331        float32\n",
      "   18           model.2.m.0.m.0.cv2.bn.weight         BatchNorm2d     False          48                [48]      1.56     0.645        float32\n",
      "   18             model.2.m.0.m.0.cv2.bn.bias         BatchNorm2d     False          48                [48]     0.168      2.39        float32\n",
      "   19         model.2.m.0.m.1.cv1.conv.weight              Conv2d     False       20736      [48, 48, 3, 3]  -0.00146    0.0329        float32\n",
      "   20           model.2.m.0.m.1.cv1.bn.weight         BatchNorm2d     False          48                [48]      1.63     0.427        float32\n",
      "   20             model.2.m.0.m.1.cv1.bn.bias         BatchNorm2d     False          48                [48]    -0.438      1.35        float32\n",
      "   21         model.2.m.0.m.1.cv2.conv.weight              Conv2d     False       20736      [48, 48, 3, 3]  -0.00123    0.0342        float32\n",
      "   22           model.2.m.0.m.1.cv2.bn.weight         BatchNorm2d     False          48                [48]      1.52     0.672        float32\n",
      "   22             model.2.m.0.m.1.cv2.bn.bias         BatchNorm2d     False          48                [48]     0.571      2.28        float32\n",
      "   23             model.2.m.1.cv1.conv.weight              Conv2d     False        4608      [48, 96, 1, 1]  -0.00451    0.0526        float32\n",
      "   24               model.2.m.1.cv1.bn.weight         BatchNorm2d     False          48                [48]      1.04     0.308        float32\n",
      "   24                 model.2.m.1.cv1.bn.bias         BatchNorm2d     False          48                [48]     0.228      1.02        float32\n",
      "   25             model.2.m.1.cv2.conv.weight              Conv2d     False        4608      [48, 96, 1, 1]  -0.00161     0.026        float32\n",
      "   26               model.2.m.1.cv2.bn.weight         BatchNorm2d     False          48                [48]      1.65     0.245        float32\n",
      "   26                 model.2.m.1.cv2.bn.bias         BatchNorm2d     False          48                [48]     -1.22     0.796        float32\n",
      "   27             model.2.m.1.cv3.conv.weight              Conv2d     False        9216      [96, 96, 1, 1]  -0.00396    0.0446        float32\n",
      "   28               model.2.m.1.cv3.bn.weight         BatchNorm2d     False          96                [96]      2.53     0.669        float32\n",
      "   28                 model.2.m.1.cv3.bn.bias         BatchNorm2d     False          96                [96]    -0.214      1.44        float32\n",
      "   29         model.2.m.1.m.0.cv1.conv.weight              Conv2d     False       20736      [48, 48, 3, 3] -0.000996    0.0333        float32\n",
      "   30           model.2.m.1.m.0.cv1.bn.weight         BatchNorm2d     False          48                [48]      1.37     0.273        float32\n",
      "   30             model.2.m.1.m.0.cv1.bn.bias         BatchNorm2d     False          48                [48]     -1.36     0.757        float32\n",
      "   31         model.2.m.1.m.0.cv2.conv.weight              Conv2d     False       20736      [48, 48, 3, 3]  -0.00443    0.0328        float32\n",
      "   32           model.2.m.1.m.0.cv2.bn.weight         BatchNorm2d     False          48                [48]      1.61     0.516        float32\n",
      "   32             model.2.m.1.m.0.cv2.bn.bias         BatchNorm2d     False          48                [48]   -0.0401      1.25        float32\n",
      "   33         model.2.m.1.m.1.cv1.conv.weight              Conv2d     False       20736      [48, 48, 3, 3]  -0.00266     0.037        float32\n",
      "   34           model.2.m.1.m.1.cv1.bn.weight         BatchNorm2d     False          48                [48]      1.09     0.186        float32\n",
      "   34             model.2.m.1.m.1.cv1.bn.bias         BatchNorm2d     False          48                [48]     -1.46     0.707        float32\n",
      "   35         model.2.m.1.m.1.cv2.conv.weight              Conv2d     False       20736      [48, 48, 3, 3]  0.000711    0.0346        float32\n",
      "   36           model.2.m.1.m.1.cv2.bn.weight         BatchNorm2d     False          48                [48]      2.05     0.724        float32\n",
      "   36             model.2.m.1.m.1.cv2.bn.bias         BatchNorm2d     False          48                [48]    -0.153       1.9        float32\n",
      "   37                     model.3.conv.weight              Conv2d     False  1.3271e+06    [384, 384, 3, 3] -0.000492    0.0138        float32\n",
      "   38                       model.3.bn.weight         BatchNorm2d     False         384               [384]      1.48     0.442        float32\n",
      "   38                         model.3.bn.bias         BatchNorm2d     False         384               [384]    -0.789      1.29        float32\n",
      "   39                 model.4.cv1.conv.weight              Conv2d     False      147456    [384, 384, 1, 1]  -0.00262    0.0302        float32\n",
      "   40                   model.4.cv1.bn.weight         BatchNorm2d     False         384               [384]      1.65     0.442        float32\n",
      "   40                     model.4.cv1.bn.bias         BatchNorm2d     False         384               [384]    -0.459      1.31        float32\n",
      "   41                 model.4.cv2.conv.weight              Conv2d     False      589824    [768, 768, 1, 1] -0.000959    0.0203        float32\n",
      "   42                   model.4.cv2.bn.weight         BatchNorm2d     False         768               [768]      1.36     0.298        float32\n",
      "   42                     model.4.cv2.bn.bias         BatchNorm2d     False         768               [768]     -2.13      0.95        float32\n",
      "   43             model.4.m.0.cv1.conv.weight              Conv2d     False       18432     [96, 192, 1, 1]  -0.00162    0.0349        float32\n",
      "   44               model.4.m.0.cv1.bn.weight         BatchNorm2d     False          96                [96]     0.823     0.456        float32\n",
      "   44                 model.4.m.0.cv1.bn.bias         BatchNorm2d     False          96                [96]    0.0842      1.06        float32\n",
      "   45             model.4.m.0.cv2.conv.weight              Conv2d     False       18432     [96, 192, 1, 1]  -0.00106    0.0232        float32\n",
      "   46               model.4.m.0.cv2.bn.weight         BatchNorm2d     False          96                [96]      0.98     0.487        float32\n",
      "   46                 model.4.m.0.cv2.bn.bias         BatchNorm2d     False          96                [96]     0.291     0.849        float32\n",
      "   47             model.4.m.0.cv3.conv.weight              Conv2d     False       36864    [192, 192, 1, 1]  -0.00253    0.0331        float32\n",
      "   48               model.4.m.0.cv3.bn.weight         BatchNorm2d     False         192               [192]      1.61     0.534        float32\n",
      "   48                 model.4.m.0.cv3.bn.bias         BatchNorm2d     False         192               [192]    -0.402      1.25        float32\n",
      "   49         model.4.m.0.m.0.cv1.conv.weight              Conv2d     False       82944      [96, 96, 3, 3] -0.000877    0.0186        float32\n",
      "   50           model.4.m.0.m.0.cv1.bn.weight         BatchNorm2d     False          96                [96]      1.52     0.421        float32\n",
      "   50             model.4.m.0.m.0.cv1.bn.bias         BatchNorm2d     False          96                [96]     -1.21      1.52        float32\n",
      "   51         model.4.m.0.m.0.cv2.conv.weight              Conv2d     False       82944      [96, 96, 3, 3]  -0.00153    0.0191        float32\n",
      "   52           model.4.m.0.m.0.cv2.bn.weight         BatchNorm2d     False          96                [96]      1.48     0.623        float32\n",
      "   52             model.4.m.0.m.0.cv2.bn.bias         BatchNorm2d     False          96                [96]    -0.805      1.35        float32\n",
      "   53         model.4.m.0.m.1.cv1.conv.weight              Conv2d     False       82944      [96, 96, 3, 3]  -0.00101    0.0205        float32\n",
      "   54           model.4.m.0.m.1.cv1.bn.weight         BatchNorm2d     False          96                [96]       1.5      0.37        float32\n",
      "   54             model.4.m.0.m.1.cv1.bn.bias         BatchNorm2d     False          96                [96]     -1.03      1.38        float32\n",
      "   55         model.4.m.0.m.1.cv2.conv.weight              Conv2d     False       82944      [96, 96, 3, 3]  -0.00124    0.0196        float32\n",
      "   56           model.4.m.0.m.1.cv2.bn.weight         BatchNorm2d     False          96                [96]      1.66     0.545        float32\n",
      "   56             model.4.m.0.m.1.cv2.bn.bias         BatchNorm2d     False          96                [96]    -0.382      1.36        float32\n",
      "   57             model.4.m.1.cv1.conv.weight              Conv2d     False       18432     [96, 192, 1, 1] -0.000938    0.0289        float32\n",
      "   58               model.4.m.1.cv1.bn.weight         BatchNorm2d     False          96                [96]      0.81       0.4        float32\n",
      "   58                 model.4.m.1.cv1.bn.bias         BatchNorm2d     False          96                [96]   0.00166     0.868        float32\n",
      "   59             model.4.m.1.cv2.conv.weight              Conv2d     False       18432     [96, 192, 1, 1] -0.000645   0.00837        float32\n",
      "   60               model.4.m.1.cv2.bn.weight         BatchNorm2d     False          96                [96]     0.648     0.258        float32\n",
      "   60                 model.4.m.1.cv2.bn.bias         BatchNorm2d     False          96                [96]    -0.521     0.251        float32\n",
      "   61             model.4.m.1.cv3.conv.weight              Conv2d     False       36864    [192, 192, 1, 1]  -0.00282    0.0265        float32\n",
      "   62               model.4.m.1.cv3.bn.weight         BatchNorm2d     False         192               [192]      1.89     0.375        float32\n",
      "   62                 model.4.m.1.cv3.bn.bias         BatchNorm2d     False         192               [192]    -0.332     0.984        float32\n",
      "   63         model.4.m.1.m.0.cv1.conv.weight              Conv2d     False       82944      [96, 96, 3, 3]  -0.00137    0.0171        float32\n",
      "   64           model.4.m.1.m.0.cv1.bn.weight         BatchNorm2d     False          96                [96]      1.43     0.234        float32\n",
      "   64             model.4.m.1.m.0.cv1.bn.bias         BatchNorm2d     False          96                [96]     -1.55     0.837        float32\n",
      "   65         model.4.m.1.m.0.cv2.conv.weight              Conv2d     False       82944      [96, 96, 3, 3]  -0.00144    0.0203        float32\n",
      "   66           model.4.m.1.m.0.cv2.bn.weight         BatchNorm2d     False          96                [96]      1.36     0.311        float32\n",
      "   66             model.4.m.1.m.0.cv2.bn.bias         BatchNorm2d     False          96                [96]    -0.595     0.987        float32\n",
      "   67         model.4.m.1.m.1.cv1.conv.weight              Conv2d     False       82944      [96, 96, 3, 3]  -0.00172    0.0209        float32\n",
      "   68           model.4.m.1.m.1.cv1.bn.weight         BatchNorm2d     False          96                [96]      1.35     0.239        float32\n",
      "   68             model.4.m.1.m.1.cv1.bn.bias         BatchNorm2d     False          96                [96]     -1.43     0.924        float32\n",
      "   69         model.4.m.1.m.1.cv2.conv.weight              Conv2d     False       82944      [96, 96, 3, 3] -0.000983    0.0207        float32\n",
      "   70           model.4.m.1.m.1.cv2.bn.weight         BatchNorm2d     False          96                [96]      1.76     0.455        float32\n",
      "   70             model.4.m.1.m.1.cv2.bn.bias         BatchNorm2d     False          96                [96]    -0.209      1.26        float32\n",
      "   71                     model.5.conv.weight              Conv2d     False 5.30842e+06    [768, 768, 3, 3] -0.000295   0.00871        float32\n",
      "   72                       model.5.bn.weight         BatchNorm2d     False         768               [768]      1.28     0.492        float32\n",
      "   72                         model.5.bn.bias         BatchNorm2d     False         768               [768]     -0.53     0.924        float32\n",
      "   73                 model.6.cv1.conv.weight              Conv2d     False      589824    [768, 768, 1, 1]  -0.00129    0.0173        float32\n",
      "   74                   model.6.cv1.bn.weight         BatchNorm2d     False         768               [768]      1.17     0.531        float32\n",
      "   74                     model.6.cv1.bn.bias         BatchNorm2d     False         768               [768]    -0.162     0.851        float32\n",
      "   75                 model.6.cv2.conv.weight              Conv2d     False 1.17965e+06   [768, 1536, 1, 1] -0.000423    0.0155        float32\n",
      "   76                   model.6.cv2.bn.weight         BatchNorm2d     False         768               [768]      1.37     0.266        float32\n",
      "   76                     model.6.cv2.bn.bias         BatchNorm2d     False         768               [768]     -1.74     0.831        float32\n",
      "   77             model.6.m.0.cv1.conv.weight              Conv2d     False       73728    [192, 384, 1, 1]  -0.00151    0.0209        float32\n",
      "   78               model.6.m.0.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.14     0.388        float32\n",
      "   78                 model.6.m.0.cv1.bn.bias         BatchNorm2d     False         192               [192]     0.125     0.791        float32\n",
      "   79             model.6.m.0.cv2.conv.weight              Conv2d     False       73728    [192, 384, 1, 1] -0.000193    0.0104        float32\n",
      "   80               model.6.m.0.cv2.bn.weight         BatchNorm2d     False         192               [192]     0.718     0.385        float32\n",
      "   80                 model.6.m.0.cv2.bn.bias         BatchNorm2d     False         192               [192]      0.42      0.56        float32\n",
      "   81             model.6.m.0.cv3.conv.weight              Conv2d     False      147456    [384, 384, 1, 1]  -0.00141    0.0192        float32\n",
      "   82               model.6.m.0.cv3.bn.weight         BatchNorm2d     False         384               [384]      1.39      0.49        float32\n",
      "   82                 model.6.m.0.cv3.bn.bias         BatchNorm2d     False         384               [384]    -0.911     0.953        float32\n",
      "   83         model.6.m.0.m.0.cv1.conv.weight              Conv2d     False      331776    [192, 192, 3, 3] -0.000818    0.0112        float32\n",
      "   84           model.6.m.0.m.0.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.22     0.341        float32\n",
      "   84             model.6.m.0.m.0.cv1.bn.bias         BatchNorm2d     False         192               [192]     -1.41     0.925        float32\n",
      "   85         model.6.m.0.m.0.cv2.conv.weight              Conv2d     False      331776    [192, 192, 3, 3] -0.000767    0.0122        float32\n",
      "   86           model.6.m.0.m.0.cv2.bn.weight         BatchNorm2d     False         192               [192]      1.47     0.454        float32\n",
      "   86             model.6.m.0.m.0.cv2.bn.bias         BatchNorm2d     False         192               [192]    -0.866     0.797        float32\n",
      "   87         model.6.m.0.m.1.cv1.conv.weight              Conv2d     False      331776    [192, 192, 3, 3] -0.000853     0.013        float32\n",
      "   88           model.6.m.0.m.1.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.29     0.284        float32\n",
      "   88             model.6.m.0.m.1.cv1.bn.bias         BatchNorm2d     False         192               [192]     -1.72     0.909        float32\n",
      "   89         model.6.m.0.m.1.cv2.conv.weight              Conv2d     False      331776    [192, 192, 3, 3] -0.000824    0.0118        float32\n",
      "   90           model.6.m.0.m.1.cv2.bn.weight         BatchNorm2d     False         192               [192]      1.47      0.41        float32\n",
      "   90             model.6.m.0.m.1.cv2.bn.bias         BatchNorm2d     False         192               [192]    -0.454      0.93        float32\n",
      "   91             model.6.m.1.cv1.conv.weight              Conv2d     False       73728    [192, 384, 1, 1]   -0.0014    0.0196        float32\n",
      "   92               model.6.m.1.cv1.bn.weight         BatchNorm2d     False         192               [192]     0.941     0.369        float32\n",
      "   92                 model.6.m.1.cv1.bn.bias         BatchNorm2d     False         192               [192]    -0.375     0.736        float32\n",
      "   93             model.6.m.1.cv2.conv.weight              Conv2d     False       73728    [192, 384, 1, 1] -0.000528   0.00587        float32\n",
      "   94               model.6.m.1.cv2.bn.weight         BatchNorm2d     False         192               [192]     0.624     0.195        float32\n",
      "   94                 model.6.m.1.cv2.bn.bias         BatchNorm2d     False         192               [192]    -0.464     0.222        float32\n",
      "   95             model.6.m.1.cv3.conv.weight              Conv2d     False      147456    [384, 384, 1, 1]   -0.0019    0.0177        float32\n",
      "   96               model.6.m.1.cv3.bn.weight         BatchNorm2d     False         384               [384]      1.69     0.276        float32\n",
      "   96                 model.6.m.1.cv3.bn.bias         BatchNorm2d     False         384               [384]    -0.686     0.813        float32\n",
      "   97         model.6.m.1.m.0.cv1.conv.weight              Conv2d     False      331776    [192, 192, 3, 3] -0.000938    0.0122        float32\n",
      "   98           model.6.m.1.m.0.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.45     0.184        float32\n",
      "   98             model.6.m.1.m.0.cv1.bn.bias         BatchNorm2d     False         192               [192]     -1.83     0.713        float32\n",
      "   99         model.6.m.1.m.0.cv2.conv.weight              Conv2d     False      331776    [192, 192, 3, 3]  -0.00118     0.014        float32\n",
      "  100           model.6.m.1.m.0.cv2.bn.weight         BatchNorm2d     False         192               [192]      1.45     0.282        float32\n",
      "  100             model.6.m.1.m.0.cv2.bn.bias         BatchNorm2d     False         192               [192]     -0.81     0.754        float32\n",
      "  101         model.6.m.1.m.1.cv1.conv.weight              Conv2d     False      331776    [192, 192, 3, 3]   -0.0011    0.0146        float32\n",
      "  102           model.6.m.1.m.1.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.39      0.24        float32\n",
      "  102             model.6.m.1.m.1.cv1.bn.bias         BatchNorm2d     False         192               [192]     -1.95     0.863        float32\n",
      "  103         model.6.m.1.m.1.cv2.conv.weight              Conv2d     False      331776    [192, 192, 3, 3] -0.000704     0.014        float32\n",
      "  104           model.6.m.1.m.1.cv2.bn.weight         BatchNorm2d     False         192               [192]      1.84     0.357        float32\n",
      "  104             model.6.m.1.m.1.cv2.bn.bias         BatchNorm2d     False         192               [192]    -0.751     0.972        float32\n",
      "  105                     model.7.conv.weight              Conv2d     False 5.30842e+06    [768, 768, 3, 3] -0.000265   0.00846        float32\n",
      "  106                       model.7.bn.weight         BatchNorm2d     False         768               [768]      1.44     0.514        float32\n",
      "  106                         model.7.bn.bias         BatchNorm2d     False         768               [768]    0.0883      1.03        float32\n",
      "  107                 model.8.cv1.conv.weight              Conv2d     False      589824    [768, 768, 1, 1]  -0.00079    0.0168        float32\n",
      "  108                   model.8.cv1.bn.weight         BatchNorm2d     False         768               [768]      1.38     0.453        float32\n",
      "  108                     model.8.cv1.bn.bias         BatchNorm2d     False         768               [768]     0.623     0.857        float32\n",
      "  109                 model.8.cv2.conv.weight              Conv2d     False 1.17965e+06   [768, 1536, 1, 1] -0.000675    0.0146        float32\n",
      "  110                   model.8.cv2.bn.weight         BatchNorm2d     False         768               [768]      1.88     0.403        float32\n",
      "  110                     model.8.cv2.bn.bias         BatchNorm2d     False         768               [768]    -0.401     0.958        float32\n",
      "  111             model.8.m.0.cv1.conv.weight              Conv2d     False       73728    [192, 384, 1, 1]  -0.00227    0.0218        float32\n",
      "  112               model.8.m.0.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.45     0.361        float32\n",
      "  112                 model.8.m.0.cv1.bn.bias         BatchNorm2d     False         192               [192]    -0.943     0.973        float32\n",
      "  113             model.8.m.0.cv2.conv.weight              Conv2d     False       73728    [192, 384, 1, 1] -0.000588   0.00905        float32\n",
      "  114               model.8.m.0.cv2.bn.weight         BatchNorm2d     False         192               [192]     0.929     0.382        float32\n",
      "  114                 model.8.m.0.cv2.bn.bias         BatchNorm2d     False         192               [192]   -0.0688     0.358        float32\n",
      "  115             model.8.m.0.cv3.conv.weight              Conv2d     False      147456    [384, 384, 1, 1]  -0.00189    0.0175        float32\n",
      "  116               model.8.m.0.cv3.bn.weight         BatchNorm2d     False         384               [384]      1.83     0.317        float32\n",
      "  116                 model.8.m.0.cv3.bn.bias         BatchNorm2d     False         384               [384]    -0.855     0.802        float32\n",
      "  117         model.8.m.0.m.0.cv1.conv.weight              Conv2d     False      331776    [192, 192, 3, 3]  -0.00121    0.0122        float32\n",
      "  118           model.8.m.0.m.0.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.46      0.24        float32\n",
      "  118             model.8.m.0.m.0.cv1.bn.bias         BatchNorm2d     False         192               [192]        -2      0.78        float32\n",
      "  119         model.8.m.0.m.0.cv2.conv.weight              Conv2d     False      331776    [192, 192, 3, 3]  -0.00118    0.0119        float32\n",
      "  120           model.8.m.0.m.0.cv2.bn.weight         BatchNorm2d     False         192               [192]      1.37     0.269        float32\n",
      "  120             model.8.m.0.m.0.cv2.bn.bias         BatchNorm2d     False         192               [192]     -1.04     0.684        float32\n",
      "  121         model.8.m.0.m.1.cv1.conv.weight              Conv2d     False      331776    [192, 192, 3, 3]  -0.00117    0.0135        float32\n",
      "  122           model.8.m.0.m.1.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.57     0.281        float32\n",
      "  122             model.8.m.0.m.1.cv1.bn.bias         BatchNorm2d     False         192               [192]      -2.3     0.878        float32\n",
      "  123         model.8.m.0.m.1.cv2.conv.weight              Conv2d     False      331776    [192, 192, 3, 3]  -0.00123    0.0118        float32\n",
      "  124           model.8.m.0.m.1.cv2.bn.weight         BatchNorm2d     False         192               [192]      1.86      0.36        float32\n",
      "  124             model.8.m.0.m.1.cv2.bn.bias         BatchNorm2d     False         192               [192]      -0.2     0.771        float32\n",
      "  125             model.8.m.1.cv1.conv.weight              Conv2d     False       73728    [192, 384, 1, 1]  -0.00137    0.0143        float32\n",
      "  126               model.8.m.1.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.03     0.371        float32\n",
      "  126                 model.8.m.1.cv1.bn.bias         BatchNorm2d     False         192               [192]    -0.508     0.751        float32\n",
      "  127             model.8.m.1.cv2.conv.weight              Conv2d     False       73728    [192, 384, 1, 1] -0.000401   0.00431        float32\n",
      "  128               model.8.m.1.cv2.bn.weight         BatchNorm2d     False         192               [192]     0.698     0.127        float32\n",
      "  128                 model.8.m.1.cv2.bn.bias         BatchNorm2d     False         192               [192]    -0.377     0.088        float32\n",
      "  129             model.8.m.1.cv3.conv.weight              Conv2d     False      147456    [384, 384, 1, 1]  -0.00125     0.011        float32\n",
      "  130               model.8.m.1.cv3.bn.weight         BatchNorm2d     False         384               [384]      1.28     0.371        float32\n",
      "  130                 model.8.m.1.cv3.bn.bias         BatchNorm2d     False         384               [384]    -0.374     0.428        float32\n",
      "  131         model.8.m.1.m.0.cv1.conv.weight              Conv2d     False      331776    [192, 192, 3, 3] -0.000676   0.00778        float32\n",
      "  132           model.8.m.1.m.0.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.18     0.367        float32\n",
      "  132             model.8.m.1.m.0.cv1.bn.bias         BatchNorm2d     False         192               [192]     -1.26     0.665        float32\n",
      "  133         model.8.m.1.m.0.cv2.conv.weight              Conv2d     False      331776    [192, 192, 3, 3]  -0.00048   0.00872        float32\n",
      "  134           model.8.m.1.m.0.cv2.bn.weight         BatchNorm2d     False         192               [192]      1.56     0.432        float32\n",
      "  134             model.8.m.1.m.0.cv2.bn.bias         BatchNorm2d     False         192               [192]    -0.712     0.621        float32\n",
      "  135         model.8.m.1.m.1.cv1.conv.weight              Conv2d     False      331776    [192, 192, 3, 3] -0.000558    0.0081        float32\n",
      "  136           model.8.m.1.m.1.cv1.bn.weight         BatchNorm2d     False         192               [192]      1.38     0.264        float32\n",
      "  136             model.8.m.1.m.1.cv1.bn.bias         BatchNorm2d     False         192               [192]    -0.944     0.442        float32\n",
      "  137         model.8.m.1.m.1.cv2.conv.weight              Conv2d     False      331776    [192, 192, 3, 3] -0.000466   0.00757        float32\n",
      "  138           model.8.m.1.m.1.cv2.bn.weight         BatchNorm2d     False         192               [192]      1.64      0.41        float32\n",
      "  138             model.8.m.1.m.1.cv2.bn.bias         BatchNorm2d     False         192               [192]    -0.334     0.562        float32\n",
      "  139                 model.9.cv1.conv.weight              Conv2d     False      589824    [768, 768, 1, 1]  -0.00198    0.0236        float32\n",
      "  140                   model.9.cv1.bn.weight         BatchNorm2d     False         768               [768]      2.17       0.4        float32\n",
      "  140                     model.9.cv1.bn.bias         BatchNorm2d     False         768               [768]    -0.861      1.04        float32\n",
      "  141                 model.9.cv2.conv.weight              Conv2d     False      589824    [768, 768, 1, 1]  -0.00134    0.0308        float32\n",
      "  142                   model.9.cv2.bn.weight         BatchNorm2d     False         768               [768]       1.1      0.25        float32\n",
      "  142                     model.9.cv2.bn.bias         BatchNorm2d     False         768               [768]     -2.14     0.832        float32\n",
      "  143        model.9.m.0.attn.qkv.conv.weight              Conv2d     False      294912    [768, 384, 1, 1] -7.28e-05    0.0196        float32\n",
      "  144          model.9.m.0.attn.qkv.bn.weight         BatchNorm2d     False         768               [768]      1.12     0.697        float32\n",
      "  144            model.9.m.0.attn.qkv.bn.bias         BatchNorm2d     False         768               [768]   0.00741     0.404        float32\n",
      "  145                model.9.m.0.attn.qkv.act            Identity     False           0                  []         -         -              -\n",
      "  146       model.9.m.0.attn.proj.conv.weight              Conv2d     False      147456    [384, 384, 1, 1] -0.000108    0.0212        float32\n",
      "  147         model.9.m.0.attn.proj.bn.weight         BatchNorm2d     False         384               [384]       0.4     0.504        float32\n",
      "  147           model.9.m.0.attn.proj.bn.bias         BatchNorm2d     False         384               [384]  2.28e-05   0.00041        float32\n",
      "  148               model.9.m.0.attn.proj.act            Identity     False           0                  []         -         -              -\n",
      "  149         model.9.m.0.attn.pe.conv.weight              Conv2d     False        3456      [384, 1, 3, 3]   -0.0272    0.0495        float32\n",
      "  150           model.9.m.0.attn.pe.bn.weight         BatchNorm2d     False         384               [384]     0.825     0.494        float32\n",
      "  150             model.9.m.0.attn.pe.bn.bias         BatchNorm2d     False         384               [384]  1.24e-05  0.000195        float32\n",
      "  151                 model.9.m.0.attn.pe.act            Identity     False           0                  []         -         -              -\n",
      "  152           model.9.m.0.ffn.0.conv.weight              Conv2d     False      294912    [768, 384, 1, 1] -0.000735    0.0241        float32\n",
      "  153             model.9.m.0.ffn.0.bn.weight         BatchNorm2d     False         768               [768]      0.98     0.253        float32\n",
      "  153               model.9.m.0.ffn.0.bn.bias         BatchNorm2d     False         768               [768]     -2.02     0.568        float32\n",
      "  154           model.9.m.0.ffn.1.conv.weight              Conv2d     False      294912    [384, 768, 1, 1] -0.000203    0.0201        float32\n",
      "  155             model.9.m.0.ffn.1.bn.weight         BatchNorm2d     False         384               [384]     0.405     0.293        float32\n",
      "  155               model.9.m.0.ffn.1.bn.bias         BatchNorm2d     False         384               [384]  4.34e-05  0.000334        float32\n",
      "  156                   model.9.m.0.ffn.1.act            Identity     False           0                  []         -         -              -\n",
      "  157        model.9.m.1.attn.qkv.conv.weight              Conv2d     False      294912    [768, 384, 1, 1]  6.07e-05    0.0256        float32\n",
      "  158          model.9.m.1.attn.qkv.bn.weight         BatchNorm2d     False         768               [768]      1.19     0.602        float32\n",
      "  158            model.9.m.1.attn.qkv.bn.bias         BatchNorm2d     False         768               [768]    0.0137     0.293        float32\n",
      "  159                model.9.m.1.attn.qkv.act            Identity     False           0                  []         -         -              -\n",
      "  160       model.9.m.1.attn.proj.conv.weight              Conv2d     False      147456    [384, 384, 1, 1]  9.25e-05    0.0283        float32\n",
      "  161         model.9.m.1.attn.proj.bn.weight         BatchNorm2d     False         384               [384]     0.752     0.324        float32\n",
      "  161           model.9.m.1.attn.proj.bn.bias         BatchNorm2d     False         384               [384]  3.98e-05  0.000227        float32\n",
      "  162               model.9.m.1.attn.proj.act            Identity     False           0                  []         -         -              -\n",
      "  163         model.9.m.1.attn.pe.conv.weight              Conv2d     False        3456      [384, 1, 3, 3]   -0.0313     0.062        float32\n",
      "  164           model.9.m.1.attn.pe.bn.weight         BatchNorm2d     False         384               [384]      1.04     0.293        float32\n",
      "  164             model.9.m.1.attn.pe.bn.bias         BatchNorm2d     False         384               [384]  -1.4e-05  0.000156        float32\n",
      "  165                 model.9.m.1.attn.pe.act            Identity     False           0                  []         -         -              -\n",
      "  166           model.9.m.1.ffn.0.conv.weight              Conv2d     False      294912    [768, 384, 1, 1] -0.000392    0.0262        float32\n",
      "  167             model.9.m.1.ffn.0.bn.weight         BatchNorm2d     False         768               [768]       1.1     0.236        float32\n",
      "  167               model.9.m.1.ffn.0.bn.bias         BatchNorm2d     False         768               [768]     -2.38       0.6        float32\n",
      "  168           model.9.m.1.ffn.1.conv.weight              Conv2d     False      294912    [384, 768, 1, 1] -3.04e-05    0.0206        float32\n",
      "  169             model.9.m.1.ffn.1.bn.weight         BatchNorm2d     False         384               [384]     0.489     0.269        float32\n",
      "  169               model.9.m.1.ffn.1.bn.bias         BatchNorm2d     False         384               [384]   4.8e-05  0.000173        float32\n",
      "  170                   model.9.m.1.ffn.1.act            Identity     False           0                  []         -         -              -\n",
      "  171               model.10.conv.conv.weight              Conv2d     False      983040   [1280, 768, 1, 1] -0.000367    0.0251        float32\n",
      "  172                 model.10.conv.bn.weight         BatchNorm2d     False        1280              [1280]      4.76     0.541        float32\n",
      "  172                   model.10.conv.bn.bias         BatchNorm2d     False        1280              [1280]     -3.82     0.724        float32\n",
      "  173                           model.10.pool   AdaptiveAvgPool2d     False           0                  []         -         -              -\n",
      "  174                           model.10.drop             Dropout     False           0                  []         -         -              -\n",
      "  175                  model.10.linear.weight              Linear     False    1.28e+06        [1000, 1280]  3.84e-06    0.0381        float32\n",
      "  175                    model.10.linear.bias              Linear     False        1000              [1000]   0.00261     0.633        float32\n",
      "YOLO11x-cls summary: 176 layers, 29,637,064 parameters, 0 gradients, 112.0 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(176, 29637064, 0, 112.0110592)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Apple Silicon\n",
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(settings.paths.model_dir/'yolo11x-cls.pt')\n",
    "model.info(detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09daddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.218 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.203 🚀 Python-3.12.11 torch-2.6.0 CPU (Apple M3)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/recognition/izutsumiTraining, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=2, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=128, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1e-24, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=data/models/yolo11x-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=v117, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/izutsumi, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/rifusaki/repos/catnip/runs/izutsumi/v117, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/rifusaki/repos/catnip/data/recognition/izutsumiTraining/train... found 196 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/rifusaki/repos/catnip/data/recognition/izutsumiTraining/val... found 48 images in 2 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 10                  -1  1    988162  ultralytics.nn.modules.head.Classify         [768, 2]                      \n",
      "YOLO11x-cls summary: 176 layers, 28,358,626 parameters, 28,358,626 gradients, 111.0 GFLOPs\n",
      "Transferred 492/494 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 48.1±10.0 MB/s, size: 9.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/rifusaki/repos/catnip/data/recognition/izutsumiTraining/train... 196 images, 0 corrupt: 100% ━━━━━━━━━━━━ 196/196 6.1Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/rifusaki/repos/catnip/data/recognition/izutsumiTraining/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 32.3±11.8 MB/s, size: 9.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/rifusaki/repos/catnip/data/recognition/izutsumiTraining/val... 48 images, 0 corrupt: 100% ━━━━━━━━━━━━ 48/48 5.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/rifusaki/repos/catnip/data/recognition/izutsumiTraining/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=1e-24' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 128 train, 128 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/rifusaki/repos/catnip/runs/izutsumi/v117\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      1/200         0G     0.7638         16        128: 23% ━━╸───────── 3/13 0.6it/s 14.2s<18.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# YOLOv8 data=\"config/izutsumiTraining11.yaml\",\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/recognition/izutsumiTraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr0\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# lower LR for finetuning\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfreeze\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# freeze backbone layers\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mruns/izutsumi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mv11\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# \"mps\", \"cuda\", \"cpu\"\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# True for Colab\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/engine/model.py:800\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/engine/trainer.py:235\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    232\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/engine/trainer.py:423\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    421\u001b[39m     loss, \u001b[38;5;28mself\u001b[39m.loss_items = unwrap_model(\u001b[38;5;28mself\u001b[39m.model).loss(batch, preds)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     loss, \u001b[38;5;28mself\u001b[39m.loss_items = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[38;5;28mself\u001b[39m.loss = loss.sum()\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK != -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/tasks.py:138\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[32m    126\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict(x, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/tasks.py:338\u001b[39m, in \u001b[36mBaseModel.loss\u001b[39m\u001b[34m(self, batch, preds)\u001b[39m\n\u001b[32m    335\u001b[39m     \u001b[38;5;28mself\u001b[39m.criterion = \u001b[38;5;28mself\u001b[39m.init_criterion()\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.criterion(preds, batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/tasks.py:139\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/tasks.py:157\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/tasks.py:180\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    181\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/modules/block.py:318\u001b[39m, in \u001b[36mC2f.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[32m    317\u001b[39m y = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.cv1(x).chunk(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m \u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv2(torch.cat(y, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/modules/block.py:318\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[32m    317\u001b[39m y = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.cv1(x).chunk(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m y.extend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.m)\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv2(torch.cat(y, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/modules/block.py:353\u001b[39m, in \u001b[36mC3.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m    352\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Forward pass through the CSP bottleneck with 3 convolutions.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv3(torch.cat((\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.cv2(x)), \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/modules/block.py:495\u001b[39m, in \u001b[36mBottleneck.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m    494\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply bottleneck with optional shortcut connection.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[38;5;28mself\u001b[39m.cv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.add \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv2(\u001b[38;5;28mself\u001b[39m.cv1(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/ultralytics/nn/modules/conv.py:81\u001b[39m, in \u001b[36mConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     72\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m    Apply convolution, batch normalization and activation to input tensor.\u001b[39;00m\n\u001b[32m     74\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \u001b[33;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/modules/activation.py:432\u001b[39m, in \u001b[36mSiLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/catnip/.pixi/envs/default/lib/python3.12/site-packages/torch/nn/functional.py:2379\u001b[39m, in \u001b[36msilu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   2377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace=inplace)\n\u001b[32m   2378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m-> \u001b[39m\u001b[32m2379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._nn.silu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# YOLOv8 data=\"config/izutsumiTraining11.yaml\",\n",
    "model.train(\n",
    "        data=\"data/recognition/izutsumiTraining\",\n",
    "        epochs=200,\n",
    "        imgsz=settings.params.img_size,\n",
    "        batch=16,\n",
    "        lr0=1e-24,       # lower LR for finetuning\n",
    "        freeze=2,      # freeze backbone layers\n",
    "        project=\"runs/izutsumi\",\n",
    "        name=\"v11\",\n",
    "        device='cpu', # \"mps\", \"cuda\", \"cpu\"\n",
    "        workers=8,\n",
    "        resume=False,\n",
    "        cache=False     # True for Colab\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e723f",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics = model.val()\n",
    "print(metrics)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b4afb",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on unseen images\n",
    "model.predict(\n",
    "    source=\"data/recognition/izutsumiTraining/val/images\",\n",
    "    save=True,\n",
    "    conf=0.5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
