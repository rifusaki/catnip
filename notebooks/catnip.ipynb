{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d232c2",
   "metadata": {},
   "source": [
    "# Catnip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0268ef9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d790b",
   "metadata": {},
   "source": [
    "### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56767293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scripts for Colab ---\n",
    "# Clone repo\n",
    "!git clone -b main --recurse-submodules https://github.com/rifusaki/catnip.git\n",
    "%cd /content/catnip\n",
    "\n",
    "# Authenticate with Google\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Install gcsfuse\n",
    "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
    "!apt -qq update\n",
    "!apt -qq install gcsfuse\n",
    "\n",
    "# Mount bucket\n",
    "!mkdir -p /content/gcs\n",
    "!gcsfuse --implicit-dirs catnip-data /content/gcs\n",
    "!ln -s /content/gcs/data /content/catnip/data\n",
    "!ln -s /content/gcs/runs /content/catnip/runs\n",
    "\n",
    "\n",
    "# Install packages not included in Colab\n",
    "%pip install ultralytics pydantic pydantic-settings omegaconf\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e836c0",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6626adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload for debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc37b22",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faec48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /Users/rifusaki/repos/catnip\n",
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
     ]
    }
   ],
   "source": [
    "# Dependencies and configuration\n",
    "from src.config import settings, setup_dirs\n",
    "\n",
    "print(\"Working directory set to:\", Path.cwd())\n",
    "izutsumiPaths, notIzutsumiPaths = setup_dirs()\n",
    "\n",
    "# For Apple Silicon\n",
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9572788",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7b7ba",
   "metadata": {},
   "source": [
    "### Panel extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5439a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.coreMPE.src.adenzu_panel.image_processing import panel\n",
    "\n",
    "\n",
    "_ = panel.extract_panels_for_images_in_folder_recursive(\n",
    "    input_dir=str(settings.paths.pages_dir),\n",
    "    output_dir=str(settings.paths.panels_dir),\n",
    "    split_joint_panels=False,   # maps to --split-joint-panels\n",
    "    fallback=True              # maps to --fallback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e7198",
   "metadata": {},
   "source": [
    "### Head crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bbf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting faces in panels:   9%|▉         | 1460/15949 [1:52:12<5:00:52,  1.25s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.050s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting faces in panels:  29%|██▉       | 4669/15949 [2:22:20<51:03,  3.68it/s]     "
     ]
    }
   ],
   "source": [
    "from src.preprocess.headExtraction import anime_extraction_recursive\n",
    "\n",
    "\n",
    "num_crops = anime_extraction_recursive(device='mps')\n",
    "print(f\"Extracted {num_crops} faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfcd928",
   "metadata": {},
   "source": [
    "## Catnip core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d86d2d",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1156e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.preparation import prepare_data\n",
    "\n",
    "prepare_data(izutsumiPaths, notIzutsumiPaths, version=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902308d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac349522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(settings.paths.model_dir/'yolo11x_izutsumiV1.pt')\n",
    "model.info(detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09daddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8 data=\"config/izutsumiTraining11.yaml\",\n",
    "model.train(\n",
    "        data=\"data/recognition/izutsumiTraining\",\n",
    "        epochs=200,\n",
    "        imgsz=settings.params.img_size,\n",
    "        batch=16,\n",
    "        lr0=1e-4,       # lower LR for finetuning\n",
    "        freeze=2,      # freeze backbone layers\n",
    "        project=\"runs/train\",\n",
    "        name=\"v11\",\n",
    "        device='cpu', # \"mps\", \"cuda\", \"cpu\"\n",
    "        workers=8,\n",
    "        resume=False,\n",
    "        cache=False     # True for Colab\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e723f",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics = model.val()\n",
    "print(metrics)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b4afb",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on unseen images\n",
    "# data/recognition/izutsumiTraining/val/**/*.jpg\n",
    "results = model.predict(\n",
    "    source=\"data/preprocess/crops/**/*.jpg\",\n",
    "    save_txt=True,\n",
    "    conf=0.5,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for r in results:\n",
    "    next(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"predictions.csv\")\n",
    "top = df.sort_values(\"confidence\", ascending=False)\n",
    "\n",
    "# Show top 10\n",
    "print(top.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
