{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dungeon Meshi â€” character retrieval (TensorFlow)\n",
    "\n",
    "A starter notebook that extracts panel crops, proposes head candidates with simple heuristics, computes embeddings with TensorFlow (MobileNetV2), and performs nearest-neighbor retrieval using scikit-learn.\n",
    "\n",
    "Place your page images in a folder and update the `PAGES_DIR` variable in the first code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/mnt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m CROPS_DIR = \u001b[33m'\u001b[39m\u001b[33m/mnt/data/dungeon_meshi_crops\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPANELS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m os.makedirs(CROPS_DIR, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSetup done. Update PAGES_DIR if needed.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:218\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:218\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:228\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 30] Read-only file system: '/mnt'"
     ]
    }
   ],
   "source": [
    "# Dependencies and configuration\n",
    "PAGES_DIR = '.data/pages'  # change this to where your JPGs are\n",
    "PANELS_DIR = '.data/panels'\n",
    "CROPS_DIR = '.data/crops'\n",
    "import os\n",
    "os.makedirs(PANELS_DIR, exist_ok=True)\n",
    "os.makedirs(CROPS_DIR, exist_ok=True)\n",
    "print('Setup done. Update PAGES_DIR if needed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple panel extraction and head-candidate extraction (OpenCV required)\n",
    "import cv2, numpy as np, glob\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_panels_from_page(page_path, out_dir, min_area=20000):\n",
    "    img = cv2.imread(page_path)\n",
    "    if img is None:\n",
    "        return []\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, th = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "    closed = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    base = Path(page_path).stem\n",
    "    saved = 0\n",
    "    for i, cnt in enumerate(contours):\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        crop = img[y:y+h, x:x+w]\n",
    "        out_path = os.path.join(out_dir, f\"{base}_panel_{i}.jpg\")\n",
    "        cv2.imwrite(out_path, crop)\n",
    "        saved += 1\n",
    "    return saved\n",
    "\n",
    "page_paths = sorted(glob.glob(os.path.join(PAGES_DIR, '*.jpg')) + glob.glob(os.path.join(PAGES_DIR, '*.png')))\n",
    "count = 0\n",
    "for p in page_paths:\n",
    "    count += extract_panels_from_page(p, PANELS_DIR)\n",
    "print('Saved', count, 'panels to', PANELS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic head candidate extraction\n",
    "import glob\n",
    "panel_paths = sorted(glob.glob(os.path.join(PANELS_DIR, '*.jpg')))\n",
    "count = 0\n",
    "for p in panel_paths:\n",
    "    img = cv2.imread(p)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, th = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(th, connectivity=8)\n",
    "    base = Path(p).stem\n",
    "    for i in range(1, num_labels):\n",
    "        x,y,w,h,area = stats[i]\n",
    "        if area < 800:\n",
    "            continue\n",
    "        aspect = w / float(h)\n",
    "        if 0.35 < aspect < 1.8:\n",
    "            pad_w = int(w*0.4); pad_h = int(h*0.6)\n",
    "            x0 = max(0, x-pad_w); y0 = max(0, y-pad_h)\n",
    "            x1 = min(img.shape[1], x+w+pad_w); y1 = min(img.shape[0], y+h+pad_h)\n",
    "            crop = img[y0:y1, x0:x1]\n",
    "            outp = os.path.join(CROPS_DIR, f\"{base}_crop_{i}.jpg\")\n",
    "            cv2.imwrite(outp, crop)\n",
    "            count += 1\n",
    "print('Saved', count, 'candidate crops to', CROPS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding model (TensorFlow MobileNetV2) and compute embeddings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "import numpy as np, json\n",
    "\n",
    "IMG_SIZE = 128\n",
    "base = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False, weights='imagenet')\n",
    "x = base.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation=None)(x)\n",
    "x = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(x)\n",
    "embed_model = models.Model(inputs=base.input, outputs=x)\n",
    "\n",
    "crop_paths = sorted(glob.glob(os.path.join(CROPS_DIR, '*.jpg')))\n",
    "print('Found', len(crop_paths), 'crops')\n",
    "if len(crop_paths) > 0:\n",
    "    def load_img(path):\n",
    "        img = Image.open(path).convert('RGB').resize((IMG_SIZE,IMG_SIZE), Image.BICUBIC)\n",
    "        return np.asarray(img)/255.0\n",
    "    X = np.stack([load_img(p) for p in crop_paths], axis=0)\n",
    "    embs = embed_model.predict(X, batch_size=64)\n",
    "    np.save('/mnt/data/embeddings.npy', embs)\n",
    "    with open('/mnt/data/crop_paths.json', 'w') as f:\n",
    "        json.dump(crop_paths, f)\n",
    "    print('Saved embeddings and paths')\n",
    "else:\n",
    "    print('No crops found; run earlier cells to produce crops.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest-neighbor search with scikit-learn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "embs = np.load('/mnt/data/embeddings.npy')\n",
    "with open('/mnt/data/crop_paths.json','r') as f:\n",
    "    crop_paths = json.load(f)\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=50, metric='cosine')\n",
    "nn.fit(embs)\n",
    "\n",
    "# Example: set seed_path to one seed Izutsumi crop on your machine\n",
    "seed_path = None\n",
    "if seed_path:\n",
    "    seed = load_img(seed_path)\n",
    "    vec = embed_model.predict(seed[np.newaxis,...])\n",
    "    dists, idxs = nn.kneighbors(vec, n_neighbors=30)\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i, idx in enumerate(idxs[0]):\n",
    "        im = Image.open(crop_paths[idx]).convert('RGB')\n",
    "        plt.subplot(5,6,i+1); plt.imshow(im.resize((128,128))); plt.title(f\"{dists[0,i]:.3f}\"); plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Set seed_path to run a sample query (path to one Izutsumi crop)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
